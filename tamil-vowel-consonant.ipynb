{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train', 'sample_submission.csv', 'test']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook \n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fc89408b570>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For converting the dataset to torchvision dataset format\n",
    "class VowelConsonantDataset(Dataset):\n",
    "    def __init__(self, file_path,train=True,transform=None):\n",
    "        self.transform = transform\n",
    "        self.file_path=file_path\n",
    "        self.train=train\n",
    "        self.file_names=[file for _,_,files in os.walk(self.file_path) for file in files]\n",
    "        self.len = len(self.file_names)\n",
    "        if self.train:\n",
    "            self.classes_mapping=self.get_classes()\n",
    "    def __len__(self):\n",
    "        return len(self.file_names)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        file_name=self.file_names[index]\n",
    "        image_data=self.pil_loader(self.file_path+\"/\"+file_name)\n",
    "        if self.transform:\n",
    "            image_data = self.transform(image_data)\n",
    "        if self.train:\n",
    "            file_name_splitted=file_name.split(\"_\")\n",
    "            Y1 = self.classes_mapping[file_name_splitted[0]]\n",
    "            Y2 = self.classes_mapping[file_name_splitted[1]]\n",
    "            z1,z2=torch.zeros(10),torch.zeros(10)\n",
    "            z1[Y1-10],z2[Y2]=1,1\n",
    "            label=torch.stack([z1,z2])\n",
    "\n",
    "            return image_data, label\n",
    "\n",
    "        else:\n",
    "            return image_data, file_name\n",
    "          \n",
    "    def pil_loader(self,path):\n",
    "        with open(path, 'rb') as f:\n",
    "            img = Image.open(f)\n",
    "            return img.convert('RGB')\n",
    "\n",
    "      \n",
    "    def get_classes(self):\n",
    "        classes=[]\n",
    "        for name in self.file_names:\n",
    "            name_splitted=name.split(\"_\")\n",
    "            classes.extend([name_splitted[0],name_splitted[1]])\n",
    "        classes=list(set(classes))\n",
    "        classes_mapping={}\n",
    "        for i,cl in enumerate(sorted(classes)):\n",
    "            classes_mapping[cl]=i\n",
    "        return classes_mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Params(object):\n",
    "    def __init__(self, batch_size, epochs, seed):\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.seed = seed\n",
    "\n",
    "args = Params(64, 40, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = VowelConsonantDataset(\"../input/train/train\",train=True,transform=transform)\n",
    "train_size = int(0.9 * len(full_data))\n",
    "test_size = len(full_data) - train_size\n",
    "\n",
    "train_data, validation_data = random_split(full_data, [train_size, test_size])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=args.batch_size, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_data, batch_size=args.batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = VowelConsonantDataset(\"../input/test/test\",train=False,transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=args.batch_size,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Model(nn.Module):\n",
    "    def __init__(self): \n",
    "        super(CNN_Model, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.vowel_classifier = nn.Sequential(\n",
    "            nn.Linear(4096, 10)\n",
    "          )          \n",
    "        self.consonant_classifier = nn.Sequential(\n",
    "            nn.Linear(4096, 10)        \n",
    "          )        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        #print(x.shape)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        #print(x.shape)\n",
    "        x = self.fc(x)\n",
    "        #print(x.shape)        \n",
    "        return self.vowel_classifier(x), self.consonant_classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch_id, data in enumerate(train_loader):\n",
    "        inputs, labels = data        \n",
    "        labels_vowel = labels[:, 0, :].data.max(1)[1]\n",
    "        labels_consonant = labels[:, 1, :].data.max(1)[1]\n",
    "        \n",
    "        inputs = inputs.to(device)\n",
    "        labels_vowel = labels_vowel.to(device)\n",
    "        labels_consonant = labels_consonant.to(device)\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        outputs_vowel, outputs_consonant = model(inputs)\n",
    "        loss = loss_fn(outputs_vowel, labels_vowel) + loss_fn(outputs_consonant, labels_consonant)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "        del inputs, labels_vowel, labels_consonant, outputs_vowel, outputs_consonant\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(epoch):\n",
    "    \n",
    "    model.eval()\n",
    "    validation_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for inputs, labels in validation_loader:\n",
    "            labels_vowel = labels[:, 0, :].data.max(1)[1]\n",
    "            labels_consonant = labels[:, 1, :].data.max(1)[1]\n",
    "        \n",
    "            inputs = inputs.to(device)\n",
    "            labels_vowel = labels_vowel.to(device)\n",
    "            labels_consonant = labels_consonant.to(device)\n",
    "            \n",
    "            outputs_vowel, outputs_consonant = model(inputs)\n",
    "            loss = loss_fn(outputs_vowel, labels_vowel) + loss_fn(outputs_consonant, labels_consonant)\n",
    "            validation_loss += loss.data.item()\n",
    "            pred_vowel = outputs_vowel.data.max(1)[1]\n",
    "            pred_consonant = outputs_consonant.data.max(1)[1]\n",
    "            correct += (pred_vowel.eq(labels_vowel.data) & pred_consonant.eq(labels_consonant.data)).sum().item()           \n",
    "            \n",
    "            del inputs, labels_vowel, labels_consonant, outputs_vowel, outputs_consonant\n",
    "            torch.cuda.empty_cache()            \n",
    "            \n",
    "        validation_loss /= len(validation_loader.dataset)\n",
    "        validation_accuracy = 100.0 * correct / len(validation_loader.dataset)\n",
    "        \n",
    "        print('\\nEpoch: {}, Validation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.\n",
    "              format(epoch, validation_loss, correct, len(validation_loader.dataset), validation_accuracy))  \n",
    "        \n",
    "        return validation_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict():\n",
    "    model.eval()\n",
    "    \n",
    "    submission = {'ImageId': [], 'Class': [], 'Index': []}\n",
    "    vowel_class_map = {0: 'V0', 1: 'V1', 2: 'V2', 3: 'V3', 4: 'V4', 5: 'V5', \n",
    "                       6: 'V6', 7: 'V7', 8: 'V8', 9: 'V9'}\n",
    "    consonant_class_map = {0: 'C0', 1: 'C1', 2: 'C2', 3: 'C3', 4: 'C4', 5: 'C5', \n",
    "                       6: 'C6', 7: 'C7', 8: 'C8', 9: 'C9'}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for inputs, file_names in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            submission['ImageId'].extend(list(file_names))\n",
    "            submission['Index'].extend(list(int(file_name.split('.')[0]) for file_name in file_names))\n",
    "            \n",
    "            outputs_vowel, outputs_consonant = model(inputs)\n",
    "            pred_vowel = list(outputs_vowel.data.max(1)[1].cpu().numpy())\n",
    "            pred_consonant = list(outputs_consonant.data.max(1)[1].cpu().numpy())\n",
    "            \n",
    "            submission['Class'].extend(list('{}_{}'.format(vowel_class_map[v], consonant_class_map[c]) \n",
    "                                            for v, c in zip(pred_vowel, pred_consonant)))\n",
    "            \n",
    "    submission = pd.DataFrame(submission)\n",
    "    submission = submission[['ImageId', 'Class', 'Index']]\n",
    "    submission = submission.sort_values(['Index'])\n",
    "    submission = submission.drop('Index', axis=1)\n",
    "    submission.to_csv(\"submisision.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if m in model.vowel_classifier or model.consonant_classifier:\n",
    "        if type(m) == nn.Linear:\n",
    "            nn.init.xavier_uniform_(m.weight, gain=1.0)\n",
    "            m.bias.data.fill_(0.01)\n",
    "    elif type(m) == nn.Conv2d or type(m) == nn.Linear:\n",
    "        nn.init.kaiming_uniform_(m.weight, a=0, mode='fan_in', nonlinearity='relu')\n",
    "        m.bias.data.fill_(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LR = 0.015, Momentum = 0.900\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d0423e4b0504832a6f25873d11f6066",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=40), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1, Validation set: Average loss: 0.0718, Accuracy: 26/1000 (3%)\n",
      "\n",
      "Maximum validation accuracy so far: 3%\n",
      "\n",
      "Epoch: 2, Validation set: Average loss: 0.0667, Accuracy: 34/1000 (3%)\n",
      "\n",
      "Maximum validation accuracy so far: 3%\n",
      "\n",
      "Epoch: 3, Validation set: Average loss: 0.0727, Accuracy: 31/1000 (3%)\n",
      "\n",
      "Maximum validation accuracy so far: 3%\n",
      "\n",
      "Epoch: 4, Validation set: Average loss: 0.0424, Accuracy: 240/1000 (24%)\n",
      "\n",
      "Maximum validation accuracy so far: 24%\n",
      "\n",
      "Epoch: 5, Validation set: Average loss: 0.0291, Accuracy: 461/1000 (46%)\n",
      "\n",
      "Maximum validation accuracy so far: 46%\n",
      "\n",
      "Epoch: 6, Validation set: Average loss: 0.0227, Accuracy: 574/1000 (57%)\n",
      "\n",
      "Maximum validation accuracy so far: 57%\n",
      "\n",
      "Epoch: 7, Validation set: Average loss: 0.0176, Accuracy: 692/1000 (69%)\n",
      "\n",
      "Maximum validation accuracy so far: 69%\n",
      "\n",
      "Epoch: 8, Validation set: Average loss: 0.0166, Accuracy: 712/1000 (71%)\n",
      "\n",
      "Maximum validation accuracy so far: 71%\n",
      "\n",
      "Epoch: 9, Validation set: Average loss: 0.0145, Accuracy: 760/1000 (76%)\n",
      "\n",
      "Maximum validation accuracy so far: 76%\n",
      "\n",
      "Epoch: 10, Validation set: Average loss: 0.0131, Accuracy: 781/1000 (78%)\n",
      "\n",
      "Maximum validation accuracy so far: 78%\n",
      "\n",
      "Epoch: 11, Validation set: Average loss: 0.0124, Accuracy: 778/1000 (78%)\n",
      "\n",
      "Maximum validation accuracy so far: 78%\n",
      "\n",
      "Epoch: 12, Validation set: Average loss: 0.0114, Accuracy: 809/1000 (81%)\n",
      "\n",
      "Maximum validation accuracy so far: 81%\n",
      "\n",
      "Epoch: 13, Validation set: Average loss: 0.0120, Accuracy: 780/1000 (78%)\n",
      "\n",
      "Maximum validation accuracy so far: 81%\n",
      "\n",
      "Epoch: 14, Validation set: Average loss: 0.0116, Accuracy: 797/1000 (80%)\n",
      "\n",
      "Maximum validation accuracy so far: 81%\n",
      "\n",
      "Epoch: 15, Validation set: Average loss: 0.0108, Accuracy: 818/1000 (82%)\n",
      "\n",
      "Maximum validation accuracy so far: 82%\n",
      "\n",
      "Epoch: 16, Validation set: Average loss: 0.0114, Accuracy: 817/1000 (82%)\n",
      "\n",
      "Maximum validation accuracy so far: 82%\n",
      "\n",
      "Epoch: 17, Validation set: Average loss: 0.0140, Accuracy: 802/1000 (80%)\n",
      "\n",
      "Maximum validation accuracy so far: 82%\n",
      "\n",
      "Epoch: 18, Validation set: Average loss: 0.0106, Accuracy: 826/1000 (83%)\n",
      "\n",
      "Maximum validation accuracy so far: 83%\n",
      "\n",
      "Epoch: 19, Validation set: Average loss: 0.0116, Accuracy: 814/1000 (81%)\n",
      "\n",
      "Maximum validation accuracy so far: 83%\n",
      "\n",
      "Epoch: 20, Validation set: Average loss: 0.0103, Accuracy: 837/1000 (84%)\n",
      "\n",
      "Maximum validation accuracy so far: 84%\n",
      "\n",
      "Epoch: 21, Validation set: Average loss: 0.0120, Accuracy: 830/1000 (83%)\n",
      "\n",
      "Maximum validation accuracy so far: 84%\n",
      "\n",
      "Epoch: 22, Validation set: Average loss: 0.0095, Accuracy: 840/1000 (84%)\n",
      "\n",
      "Maximum validation accuracy so far: 84%\n",
      "\n",
      "Epoch: 23, Validation set: Average loss: 0.0123, Accuracy: 809/1000 (81%)\n",
      "\n",
      "Maximum validation accuracy so far: 84%\n",
      "\n",
      "Epoch: 24, Validation set: Average loss: 0.0106, Accuracy: 839/1000 (84%)\n",
      "\n",
      "Maximum validation accuracy so far: 84%\n",
      "\n",
      "Epoch: 25, Validation set: Average loss: 0.0122, Accuracy: 827/1000 (83%)\n",
      "\n",
      "Maximum validation accuracy so far: 84%\n",
      "\n",
      "Epoch: 26, Validation set: Average loss: 0.0127, Accuracy: 816/1000 (82%)\n",
      "\n",
      "Maximum validation accuracy so far: 84%\n",
      "\n",
      "Epoch: 27, Validation set: Average loss: 0.0114, Accuracy: 833/1000 (83%)\n",
      "\n",
      "Maximum validation accuracy so far: 84%\n",
      "\n",
      "Epoch: 28, Validation set: Average loss: 0.0138, Accuracy: 805/1000 (80%)\n",
      "\n",
      "Maximum validation accuracy so far: 84%\n",
      "\n",
      "Epoch: 29, Validation set: Average loss: 0.0112, Accuracy: 829/1000 (83%)\n",
      "\n",
      "Maximum validation accuracy so far: 84%\n",
      "\n",
      "Epoch: 30, Validation set: Average loss: 0.0114, Accuracy: 845/1000 (84%)\n",
      "\n",
      "Maximum validation accuracy so far: 84%\n",
      "\n",
      "Epoch: 31, Validation set: Average loss: 0.0131, Accuracy: 793/1000 (79%)\n",
      "\n",
      "Maximum validation accuracy so far: 84%\n",
      "\n",
      "Epoch: 32, Validation set: Average loss: 0.0119, Accuracy: 819/1000 (82%)\n",
      "\n",
      "Maximum validation accuracy so far: 84%\n",
      "\n",
      "Epoch: 33, Validation set: Average loss: 0.0111, Accuracy: 846/1000 (85%)\n",
      "\n",
      "Maximum validation accuracy so far: 85%\n",
      "\n",
      "Epoch: 34, Validation set: Average loss: 0.0152, Accuracy: 799/1000 (80%)\n",
      "\n",
      "Maximum validation accuracy so far: 85%\n",
      "\n",
      "Epoch: 35, Validation set: Average loss: 0.0116, Accuracy: 837/1000 (84%)\n",
      "\n",
      "Maximum validation accuracy so far: 85%\n",
      "\n",
      "Epoch: 36, Validation set: Average loss: 0.0114, Accuracy: 837/1000 (84%)\n",
      "\n",
      "Maximum validation accuracy so far: 85%\n",
      "\n",
      "Epoch: 37, Validation set: Average loss: 0.0121, Accuracy: 860/1000 (86%)\n",
      "\n",
      "Maximum validation accuracy so far: 86%\n",
      "\n",
      "Epoch: 38, Validation set: Average loss: 0.0118, Accuracy: 829/1000 (83%)\n",
      "\n",
      "Maximum validation accuracy so far: 86%\n",
      "\n",
      "Epoch: 39, Validation set: Average loss: 0.0128, Accuracy: 832/1000 (83%)\n",
      "\n",
      "Maximum validation accuracy so far: 86%\n",
      "\n",
      "Epoch: 40, Validation set: Average loss: 0.0114, Accuracy: 822/1000 (82%)\n",
      "\n",
      "Maximum validation accuracy so far: 86%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_validation_accuracy = 0\n",
    "\n",
    "lr = 0.015\n",
    "momentum = 0.9\n",
    "print('\\nLR = %.3f, Momentum = %.3f\\n' % (lr, momentum))\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "model = CNN_Model()\n",
    "model.apply(init_weights)\n",
    "model.to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = optim.SGD(model.parameters(), lr=lr, momentum = momentum, nesterov=True)\n",
    "\n",
    "for epoch in tqdm_notebook(range(1, args.epochs + 1), total=args.epochs, unit=\"epoch\"):\n",
    "    train(epoch)\n",
    "    validation_accuracy = validate(epoch)\n",
    "    \n",
    "    if validation_accuracy > max_validation_accuracy:\n",
    "        max_validation_accuracy = validation_accuracy\n",
    "        best_model = copy.deepcopy(model.state_dict())\n",
    "    print(\"Maximum validation accuracy so far: {:.0f}%\".format(max_validation_accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03f039b249554f0988fba44687e513bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1, Validation set: Average loss: 0.0101, Accuracy: 862/1000 (86%)\n",
      "\n",
      "Maximum validation accuracy so far: 86%\n",
      "\n",
      "Epoch: 2, Validation set: Average loss: 0.0098, Accuracy: 861/1000 (86%)\n",
      "\n",
      "Maximum validation accuracy so far: 86%\n",
      "\n",
      "Epoch: 3, Validation set: Average loss: 0.0096, Accuracy: 865/1000 (86%)\n",
      "\n",
      "Maximum validation accuracy so far: 86%\n",
      "\n",
      "Epoch: 4, Validation set: Average loss: 0.0094, Accuracy: 868/1000 (87%)\n",
      "\n",
      "Maximum validation accuracy so far: 87%\n",
      "\n",
      "Epoch: 5, Validation set: Average loss: 0.0096, Accuracy: 865/1000 (86%)\n",
      "\n",
      "Maximum validation accuracy so far: 87%\n",
      "\n",
      "Epoch: 6, Validation set: Average loss: 0.0093, Accuracy: 866/1000 (87%)\n",
      "\n",
      "Maximum validation accuracy so far: 87%\n",
      "\n",
      "Epoch: 7, Validation set: Average loss: 0.0094, Accuracy: 867/1000 (87%)\n",
      "\n",
      "Maximum validation accuracy so far: 87%\n",
      "\n",
      "Epoch: 8, Validation set: Average loss: 0.0094, Accuracy: 872/1000 (87%)\n",
      "\n",
      "Maximum validation accuracy so far: 87%\n",
      "\n",
      "Epoch: 9, Validation set: Average loss: 0.0095, Accuracy: 868/1000 (87%)\n",
      "\n",
      "Maximum validation accuracy so far: 87%\n",
      "\n",
      "Epoch: 10, Validation set: Average loss: 0.0094, Accuracy: 870/1000 (87%)\n",
      "\n",
      "Maximum validation accuracy so far: 87%\n",
      "\n",
      "Epoch: 11, Validation set: Average loss: 0.0096, Accuracy: 867/1000 (87%)\n",
      "\n",
      "Maximum validation accuracy so far: 87%\n",
      "\n",
      "Epoch: 12, Validation set: Average loss: 0.0099, Accuracy: 869/1000 (87%)\n",
      "\n",
      "Maximum validation accuracy so far: 87%\n",
      "\n",
      "Epoch: 13, Validation set: Average loss: 0.0097, Accuracy: 870/1000 (87%)\n",
      "\n",
      "Maximum validation accuracy so far: 87%\n",
      "\n",
      "Epoch: 14, Validation set: Average loss: 0.0096, Accuracy: 868/1000 (87%)\n",
      "\n",
      "Maximum validation accuracy so far: 87%\n",
      "\n",
      "Epoch: 15, Validation set: Average loss: 0.0096, Accuracy: 868/1000 (87%)\n",
      "\n",
      "Maximum validation accuracy so far: 87%\n",
      "\n",
      "Epoch: 16, Validation set: Average loss: 0.0098, Accuracy: 869/1000 (87%)\n",
      "\n",
      "Maximum validation accuracy so far: 87%\n",
      "\n",
      "Epoch: 17, Validation set: Average loss: 0.0099, Accuracy: 867/1000 (87%)\n",
      "\n",
      "Maximum validation accuracy so far: 87%\n",
      "\n",
      "Epoch: 18, Validation set: Average loss: 0.0099, Accuracy: 869/1000 (87%)\n",
      "\n",
      "Maximum validation accuracy so far: 87%\n",
      "\n",
      "Epoch: 19, Validation set: Average loss: 0.0102, Accuracy: 868/1000 (87%)\n",
      "\n",
      "Maximum validation accuracy so far: 87%\n",
      "\n",
      "Epoch: 20, Validation set: Average loss: 0.0100, Accuracy: 870/1000 (87%)\n",
      "\n",
      "Maximum validation accuracy so far: 87%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(best_model)\n",
    "\n",
    "opt = optim.SGD(model.parameters(), lr=0.001, momentum = 0.8, nesterov=True)\n",
    "args.epochs = 20\n",
    "\n",
    "for epoch in tqdm_notebook(range(1, args.epochs + 1), total=args.epochs, unit=\"epoch\"):\n",
    "    train(epoch)\n",
    "    validation_accuracy = validate(epoch)\n",
    "\n",
    "    if validation_accuracy > max_validation_accuracy:\n",
    "        max_validation_accuracy = validation_accuracy\n",
    "        best_model = copy.deepcopy(model.state_dict())\n",
    "    print(\"Maximum validation accuracy so far: {:.0f}%\".format(max_validation_accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(best_model)\n",
    "predict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
